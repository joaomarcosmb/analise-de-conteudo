# AnÃ¡lise de ConteÃºdo Automatizada com PLN e IA

Este projeto implementa uma versÃ£o automatizada da tÃ©cnica de AnÃ¡lise de ConteÃºdo de Laurence Bardin utilizando Processamento de Linguagem Natural (PLN) e InteligÃªncia Artificial. A ferramenta auxilia pesquisadores na anÃ¡lise sistemÃ¡tica de conteÃºdo textual de transcriÃ§Ãµes de entrevistas*, seguindo as trÃªs fases principais propostas por Bardin: prÃ©-anÃ¡lise, exploraÃ§Ã£o do material e tratamento dos resultados/interpretaÃ§Ã£o.

O uso da InteligÃªncia Artificial Ã© feito de forma local, isto Ã©, o LLM (Large Language Model) Ã© operado em uma mÃ¡quina proprietÃ¡ria (localmente), garantindo o controle e a seguranÃ§a dos dados analisados. 

\* A ferramenta pode ser adaptada para outros tipos de textos, como artigos, relatÃ³rios, etc.

## ğŸ¯ CaracterÃ­sticas Principais

- ImplementaÃ§Ã£o automatizada das trÃªs fases da AnÃ¡lise de ConteÃºdo de Bardin
- Processamento de textos em portuguÃªs utilizando spaCy
- AnÃ¡lise semÃ¢ntica avanÃ§ada com modelos de IA
- GeraÃ§Ã£o de visualizaÃ§Ãµes e relatÃ³rios
- ConfiguraÃ§Ã£o flexÃ­vel via arquivo YAML
- Suporte a mÃºltiplos formatos de entrada

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3.10+
- spaCy (PLN)
- NLTK
- scikit-learn
- pandas
- numpy
- matplotlib
- wordcloud
- OpenAI API (opcional)

Nota: O modelo utilizado neste exemplo Ã© o Gemma 3, o modelo de linguagem de cÃ³digo aberto do Google. A ferramenta utilizada para rodar o LLM localmente foi o [Ollama](https://ollama.com/).

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/joaomarcosmb/analise-de-conteudo
cd analise-de-conteudo
```

2. Crie um ambiente virtual (recomendado):
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
.\venv\Scripts\activate  # Windows
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

4. Baixe o modelo do spaCy para portuguÃªs:
```bash
python -m spacy download pt_core_news_md
```

## âš™ï¸ ConfiguraÃ§Ã£o

O arquivo `config.yaml` permite personalizar diversos aspectos da anÃ¡lise:

- DiretÃ³rios de entrada/saÃ­da
- ParÃ¢metros de processamento de texto
- ConfiguraÃ§Ãµes de visualizaÃ§Ã£o
- Ajustes dos algoritmos de PLN e IA

## ğŸ” Como Usar

1. Coloque seus arquivos de texto para anÃ¡lise no diretÃ³rio de entrada especificado em `config.yaml`

2. Execute o script principal:
```bash
python main.py
```

3. Os resultados serÃ£o gerados no diretÃ³rio de saÃ­da configurado

## ğŸ“Š Estrutura do Projeto

```
.
â”œâ”€â”€ data/               # DiretÃ³rio para dados de entrada e saÃ­da
â”œâ”€â”€ src/               # CÃ³digo fonte do projeto
â”‚   â”œâ”€â”€ pre_analysis/  # ImplementaÃ§Ã£o da fase de prÃ©-anÃ¡lise
â”‚   â”œâ”€â”€ exploration/   # ImplementaÃ§Ã£o da fase de exploraÃ§Ã£o
â”‚   â”œâ”€â”€ interpretation/# ImplementaÃ§Ã£o da fase de interpretaÃ§Ã£o
â”‚   â””â”€â”€ utils/        # UtilitÃ¡rios e funÃ§Ãµes auxiliares
â”œâ”€â”€ config.yaml        # Arquivo de configuraÃ§Ã£o
â”œâ”€â”€ main.py           # Script principal
â””â”€â”€ requirements.txt  # DependÃªncias do projeto
```

## ğŸ“ Fases da AnÃ¡lise

### 1. PrÃ©-anÃ¡lise
- Leitura flutuante automatizada
- PreparaÃ§Ã£o do material
- NormalizaÃ§Ã£o do texto
- TokenizaÃ§Ã£o e lematizaÃ§Ã£o
- RemoÃ§Ã£o de stopwords

### 2. ExploraÃ§Ã£o do Material
- IdentificaÃ§Ã£o automÃ¡tica de unidades de registro
- CategorizaÃ§Ã£o assistida por IA
- AnÃ¡lise de frequÃªncia
- ExtraÃ§Ã£o de temas
- GeraÃ§Ã£o de visualizaÃ§Ãµes

### 3. Tratamento dos Resultados e InterpretaÃ§Ã£o
- AnÃ¡lise estatÃ­stica
- GeraÃ§Ã£o de insights
- VisualizaÃ§Ã£o de resultados
- ExportaÃ§Ã£o de relatÃ³rios

## ğŸ“ˆ SaÃ­das

O sistema gera os seguintes tipos de anÃ¡lises e visualizaÃ§Ãµes:

- Nuvens de palavras
- Boxplot da distribuiÃ§Ã£o de relevÃ¢ncia por tema
- Heatmap da distribuiÃ§Ã£o de temas por documento
- GrÃ¡fico de barras dos temas mais relevantes
- RelatÃ³rios detalhados em formato estruturado

## ğŸ’­ Outras ConsideraÃ§Ãµes
- O nÃºmero de arquivos de entrada nÃ£o pode ser menor que a quantidade de clusters (`num_clusters`) configurada no `config.yaml`. O nÃ£o cumprimento dessa condiÃ§Ã£o pode resultar em erros.
- Os parÃ¢metros de anÃ¡lise no `config.yaml` tÃªm impactos significativos nos resultados:
  - `num_clusters`: Um nÃºmero maior de clusters pode resultar em temas mais especÃ­ficos e detalhados, mas pode tambÃ©m fragmentar demais a anÃ¡lise. Um nÃºmero menor tende a gerar temas mais abrangentes e generalistas.
  - `min_word_freq`: Aumentar este valor filtra palavras menos frequentes, focando apenas nos termos mais relevantes. Reduzir pode incluir termos mais raros, mas pode introduzir ruÃ­do na anÃ¡lise.
  - `max_df`: Este parÃ¢metro controla a frequÃªncia mÃ¡xima de documentos em que uma palavra pode aparecer. Reduzir este valor ajuda a identificar termos mais especÃ­ficos, enquanto aumentar permite capturar palavras mais comuns entre os documentos.
- Os exemplos de arquivos de texto estÃ£o disponÃ­veis na pasta `data` para avaliaÃ§Ã£o. Na pasta `input` hÃ¡ as transcriÃ§Ãµes de entrevistas que foram usadas como exemplos, e na pasta `output` hÃ¡ os resultados da anÃ¡lise desses arquivos.
- A anÃ¡lise de conteÃºdo Ã© uma tÃ©cnica **qualitativa**, e, por mais que haja uma certa automaÃ§Ã£o desse processo com a ajuda da IA, **a interpretaÃ§Ã£o dos resultados Ã© de responsabilidade do pesquisador**.

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, sinta-se Ã  vontade para submeter pull requests ou abrir issues para discutir melhorias.

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

## ğŸ“š ReferÃªncia

- BARDIN, L. AnÃ¡lise de conteÃºdo. SÃ£o Paulo: EdiÃ§Ãµes 70, 2011.